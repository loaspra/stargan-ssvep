{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stargan Main: Data partition for training and testing of the StargGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 segment and filter\n",
    "\n",
    "Create the windows of SSVEP signals for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils2 import generate_ref_signal\n",
    "from core.utils2 import fbcca\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from core.utils import segment_and_filter_all_subjects\n",
    "\n",
    "import random\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants: \n",
    "SRC_DIR = './data/processed'\n",
    "TARGET_DIR = './data/final'\n",
    "WINDOW_SIZE = 1024\n",
    "LOWCUT = 6\n",
    "HIGHCUT = 54\n",
    "FS = 250\n",
    "ORDER = 6\n",
    "\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "# def segment_and_filter_all_subjects(src_dir, target_dir, window_size, lowcut, highcut, fs, order=6):\n",
    "segment_and_filter_all_subjects(SRC_DIR, TARGET_DIR, WINDOW_SIZE, LOWCUT, HIGHCUT, FS, ORDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# get the ref signals\n",
    "N = 1024\n",
    "FS = 250\n",
    "N_HARMONICS = 3\n",
    "N_SUBBANDS = 6\n",
    "FREQS = [8, 10, 12, 14]\n",
    "LOWEST_FREQ = 2\n",
    "UPMOST_FREQ = 54\n",
    "W = 2.2\n",
    "IDX_FREQS = [0, 2, 4, 6] # [8, 10, 12, 14]\n",
    "DATA_DIR = \"./data/final\"\n",
    "FREQ_PHASE_SRC = \"./data/raw/Freq_Phase.mat\"\n",
    "\n",
    "ref_signals = generate_ref_signal(FREQ_PHASE_SRC, freqs=FREQS, N=N, n_harmonics=N_HARMONICS, fs=FS)\n",
    "\n",
    "accuracies = np.empty((35, len(IDX_FREQS)))\n",
    "for i in range(1, 36):\n",
    "    for freq in IDX_FREQS:\n",
    "        actual_freq = IDX_FREQS.index(freq)\n",
    "        label_dir = os.path.join(DATA_DIR, str(freq))\n",
    "        for j in range(0, 4):\n",
    "            file_path = os.path.join(label_dir, \"S\" + str(i) + \"_\" + str(j) + \".npy\")\n",
    "            if os.path.exists(file_path):\n",
    "                segment = np.load(file_path).swapaxes(0, 1)\n",
    "                pred = fbcca(segment, FS, N_SUBBANDS, \"M1\", W, ref_signals, LOWEST_FREQ, UPMOST_FREQ)\n",
    "            accuracies[i-1, actual_freq] = 1 if pred == actual_freq + 1 else 0\n",
    "\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_means = np.mean(accuracies, axis=1)\n",
    "perfect_idx = np.where(acc_means == 1)[0]\n",
    "perfect_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split de data\n",
    "\n",
    "Depending on the accuracy of each subject. We will train the model only with perfect scoring subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a total of 192 samples to process\n",
      "Using a total of 192 samples to process\n",
      "Using a total of 192 samples to process\n",
      "Using a total of 192 samples to process\n",
      "['0', '2', '4', '6']\n"
     ]
    }
   ],
   "source": [
    "SRC_DIR = \"./data/final\"\n",
    "TARGET_DIR = \"./data\"\n",
    "SPLIT_RATIO = 0.85 # for train/validation\n",
    "\n",
    "labels = os.listdir(SRC_DIR)\n",
    "for label in labels:\n",
    "    label_dir = os.path.join(SRC_DIR, label)\n",
    "    files = os.listdir(label_dir)\n",
    "    # Filter the files to only use the perfect accuracies\n",
    "    files = [file for file in files if int(file.split(\"_\")[0][1:]) in perfect_idx]\n",
    "    print(f\"Using a total of {len(files)} samples to process\")\n",
    "    random.shuffle(files)\n",
    "    split_idx = int(len(files) * SPLIT_RATIO)\n",
    "    train_files = files[:split_idx]\n",
    "    val_files = files[split_idx:]\n",
    "    train_dir = os.path.join(TARGET_DIR, \"train\", label)\n",
    "    val_dir = os.path.join(TARGET_DIR, \"val\", label)\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(label_dir, file), os.path.join(train_dir, file))\n",
    "    for file in val_files:\n",
    "        shutil.copy(os.path.join(label_dir, file), os.path.join(val_dir, file))\n",
    "\n",
    "# finally, rename the labels folders to 0, 1, 2 ... N instead of 2, 4, 6, 8\n",
    "files = sorted(os.listdir(\"data/train/\"))\n",
    "print(files)\n",
    "for file in files:\n",
    "    shutil.move(\"data/train/\" + file, \"data/train/\" + str(files.index(file)))\n",
    "    shutil.move(\"data/val/\" + file, \"data/val/\" + str(files.index(file)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train of the StarGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'stargan2 (Python 3.12.2)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n stargan2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%conda install -n stargan2 ipykernel --update-deps --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/loaspr/anaconda3/envs/starganV2/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/loaspr/anaconda3/envs/starganV2/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/loaspr/anaconda3/envs/starganV2/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/loaspr/anaconda3/envs/starganV2/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/loaspr/anaconda3/envs/starganV2/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/loaspr/anaconda3/envs/starganV2/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Training on cuda\n",
      "Number of parameters of generator: 12112129\n",
      "Number of parameters of mapping_network: 4079872\n",
      "Number of parameters of style_encoder: 7008622\n",
      "Number of parameters of discriminator: 6879346\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader to fetch source images during the training phase...\n",
      "Preparing DataLoader to fetch reference images during the training phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Start training...\n",
      "Elapsed time [0:00:08], Iteration [10/5000], D/latent_real: [0.0004] D/latent_fake: [0.0177] D/latent_reg: [0.0010] D/ref_real: [0.0005] D/ref_fake: [0.0062] D/ref_reg: [0.0010] G/latent_adv: [9.2899] G/latent_sty: [0.9560] G/latent_ds: [0.4710] G/latent_cyc: [4.5077] G/ref_adv: [6.4575] G/ref_sty: [0.0690] G/ref_ds: [0.0368] G/ref_cyc: [4.5105] G/lambda_ds: [0.9980]\n",
      "Elapsed time [0:00:10], Iteration [20/5000], D/latent_real: [0.0001] D/latent_fake: [0.0013] D/latent_reg: [0.0014] D/ref_real: [0.0001] D/ref_fake: [0.0002] D/ref_reg: [0.0013] G/latent_adv: [10.8693] G/latent_sty: [0.6697] G/latent_ds: [0.1977] G/latent_cyc: [4.8753] G/ref_adv: [9.0049] G/ref_sty: [0.0631] G/ref_ds: [0.0387] G/ref_cyc: [4.8746] G/lambda_ds: [0.9960]\n",
      "Elapsed time [0:00:12], Iteration [30/5000], D/latent_real: [0.0002] D/latent_fake: [0.0000] D/latent_reg: [0.0018] D/ref_real: [0.0002] D/ref_fake: [0.0002] D/ref_reg: [0.0016] G/latent_adv: [13.8646] G/latent_sty: [0.6793] G/latent_ds: [0.1660] G/latent_cyc: [4.4757] G/ref_adv: [12.0813] G/ref_sty: [0.1268] G/ref_ds: [0.0158] G/ref_cyc: [4.4767] G/lambda_ds: [0.9940]\n",
      "Elapsed time [0:00:14], Iteration [40/5000], D/latent_real: [0.0009] D/latent_fake: [0.0000] D/latent_reg: [0.0016] D/ref_real: [0.0007] D/ref_fake: [0.0001] D/ref_reg: [0.0017] G/latent_adv: [12.1903] G/latent_sty: [0.5874] G/latent_ds: [0.1971] G/latent_cyc: [5.1715] G/ref_adv: [9.3065] G/ref_sty: [0.1252] G/ref_ds: [0.0075] G/ref_cyc: [5.1528] G/lambda_ds: [0.9920]\n",
      "Elapsed time [0:00:15], Iteration [50/5000], D/latent_real: [0.0019] D/latent_fake: [0.5692] D/latent_reg: [0.0027] D/ref_real: [0.0018] D/ref_fake: [0.5103] D/ref_reg: [0.0027] G/latent_adv: [1.1590] G/latent_sty: [0.5206] G/latent_ds: [0.4447] G/latent_cyc: [5.1098] G/ref_adv: [1.1630] G/ref_sty: [0.1531] G/ref_ds: [0.0238] G/ref_cyc: [5.1064] G/lambda_ds: [0.9900]\n",
      "Elapsed time [0:00:17], Iteration [60/5000], D/latent_real: [0.0014] D/latent_fake: [0.0024] D/latent_reg: [0.0050] D/ref_real: [0.0014] D/ref_fake: [0.0022] D/ref_reg: [0.0050] G/latent_adv: [7.5156] G/latent_sty: [0.5087] G/latent_ds: [0.3292] G/latent_cyc: [6.1049] G/ref_adv: [7.2422] G/ref_sty: [0.0739] G/ref_ds: [0.0280] G/ref_cyc: [6.0940] G/lambda_ds: [0.9880]\n",
      "Elapsed time [0:00:19], Iteration [70/5000], D/latent_real: [0.0068] D/latent_fake: [0.0006] D/latent_reg: [0.0047] D/ref_real: [0.0052] D/ref_fake: [0.0007] D/ref_reg: [0.0050] G/latent_adv: [7.9795] G/latent_sty: [0.6213] G/latent_ds: [0.3469] G/latent_cyc: [4.7572] G/ref_adv: [7.7312] G/ref_sty: [0.1148] G/ref_ds: [0.0219] G/ref_cyc: [4.7490] G/lambda_ds: [0.9860]\n",
      "Elapsed time [0:00:21], Iteration [80/5000], D/latent_real: [0.0050] D/latent_fake: [0.0004] D/latent_reg: [0.0057] D/ref_real: [0.0041] D/ref_fake: [0.0005] D/ref_reg: [0.0059] G/latent_adv: [8.2326] G/latent_sty: [0.5084] G/latent_ds: [0.4136] G/latent_cyc: [4.2193] G/ref_adv: [7.9239] G/ref_sty: [0.0491] G/ref_ds: [0.0150] G/ref_cyc: [4.2099] G/lambda_ds: [0.9840]\n",
      "Elapsed time [0:00:23], Iteration [90/5000], D/latent_real: [0.0000] D/latent_fake: [0.0004] D/latent_reg: [0.0042] D/ref_real: [0.0000] D/ref_fake: [0.0004] D/ref_reg: [0.0040] G/latent_adv: [8.3729] G/latent_sty: [0.4722] G/latent_ds: [0.4257] G/latent_cyc: [6.3484] G/ref_adv: [7.8315] G/ref_sty: [0.0355] G/ref_ds: [0.0162] G/ref_cyc: [6.3315] G/lambda_ds: [0.9820]\n",
      "Elapsed time [0:00:25], Iteration [100/5000], D/latent_real: [0.0011] D/latent_fake: [0.0003] D/latent_reg: [0.0043] D/ref_real: [0.0011] D/ref_fake: [0.0003] D/ref_reg: [0.0042] G/latent_adv: [8.5958] G/latent_sty: [0.5794] G/latent_ds: [0.3667] G/latent_cyc: [4.1930] G/ref_adv: [8.1993] G/ref_sty: [0.0465] G/ref_ds: [0.0058] G/ref_cyc: [4.1790] G/lambda_ds: [0.9800]\n",
      "Elapsed time [0:00:27], Iteration [110/5000], D/latent_real: [0.0000] D/latent_fake: [0.0002] D/latent_reg: [0.0039] D/ref_real: [0.0000] D/ref_fake: [0.0004] D/ref_reg: [0.0037] G/latent_adv: [8.9347] G/latent_sty: [0.6040] G/latent_ds: [0.4265] G/latent_cyc: [5.9780] G/ref_adv: [8.1541] G/ref_sty: [0.0248] G/ref_ds: [0.0035] G/ref_cyc: [5.9850] G/lambda_ds: [0.9780]\n",
      "Elapsed time [0:00:29], Iteration [120/5000], D/latent_real: [0.0018] D/latent_fake: [0.0002] D/latent_reg: [0.0031] D/ref_real: [0.0015] D/ref_fake: [0.0003] D/ref_reg: [0.0032] G/latent_adv: [8.6828] G/latent_sty: [0.5206] G/latent_ds: [0.3174] G/latent_cyc: [5.9603] G/ref_adv: [7.9109] G/ref_sty: [0.0203] G/ref_ds: [0.0040] G/ref_cyc: [5.9270] G/lambda_ds: [0.9760]\n",
      "Elapsed time [0:00:31], Iteration [130/5000], D/latent_real: [0.0000] D/latent_fake: [0.0005] D/latent_reg: [0.0035] D/ref_real: [0.0000] D/ref_fake: [0.0004] D/ref_reg: [0.0032] G/latent_adv: [8.3603] G/latent_sty: [0.4872] G/latent_ds: [0.4780] G/latent_cyc: [7.1075] G/ref_adv: [8.0252] G/ref_sty: [0.0244] G/ref_ds: [0.0058] G/ref_cyc: [7.1131] G/lambda_ds: [0.9740]\n",
      "Elapsed time [0:00:33], Iteration [140/5000], D/latent_real: [0.0000] D/latent_fake: [0.0002] D/latent_reg: [0.0026] D/ref_real: [0.0000] D/ref_fake: [0.0002] D/ref_reg: [0.0025] G/latent_adv: [9.0069] G/latent_sty: [0.5405] G/latent_ds: [0.3871] G/latent_cyc: [6.1582] G/ref_adv: [8.5500] G/ref_sty: [0.0183] G/ref_ds: [0.0060] G/ref_cyc: [6.1413] G/lambda_ds: [0.9720]\n",
      "Elapsed time [0:00:35], Iteration [150/5000], D/latent_real: [0.0046] D/latent_fake: [0.0001] D/latent_reg: [0.0018] D/ref_real: [0.0023] D/ref_fake: [0.0002] D/ref_reg: [0.0021] G/latent_adv: [8.6295] G/latent_sty: [0.4786] G/latent_ds: [0.4803] G/latent_cyc: [5.4541] G/ref_adv: [8.2774] G/ref_sty: [0.0210] G/ref_ds: [0.0040] G/ref_cyc: [5.4109] G/lambda_ds: [0.9700]\n",
      "Elapsed time [0:00:37], Iteration [160/5000], D/latent_real: [0.0001] D/latent_fake: [0.0001] D/latent_reg: [0.0024] D/ref_real: [0.0001] D/ref_fake: [0.0001] D/ref_reg: [0.0022] G/latent_adv: [10.1970] G/latent_sty: [0.5268] G/latent_ds: [0.4263] G/latent_cyc: [4.8266] G/ref_adv: [9.6153] G/ref_sty: [0.0312] G/ref_ds: [0.0134] G/ref_cyc: [4.8424] G/lambda_ds: [0.9680]\n",
      "Elapsed time [0:00:40], Iteration [170/5000], D/latent_real: [0.2629] D/latent_fake: [0.7126] D/latent_reg: [0.0001] D/ref_real: [0.1947] D/ref_fake: [0.6933] D/ref_reg: [0.0002] G/latent_adv: [0.7430] G/latent_sty: [0.5117] G/latent_ds: [0.9544] G/latent_cyc: [4.3673] G/ref_adv: [0.7470] G/ref_sty: [0.0540] G/ref_ds: [0.0214] G/ref_cyc: [4.3431] G/lambda_ds: [0.9660]\n",
      "Elapsed time [0:00:42], Iteration [180/5000], D/latent_real: [0.0038] D/latent_fake: [0.0039] D/latent_reg: [0.0023] D/ref_real: [0.0035] D/ref_fake: [0.0040] D/ref_reg: [0.0024] G/latent_adv: [6.2279] G/latent_sty: [0.5051] G/latent_ds: [0.5655] G/latent_cyc: [4.9326] G/ref_adv: [5.7299] G/ref_sty: [0.0237] G/ref_ds: [0.0081] G/ref_cyc: [4.9349] G/lambda_ds: [0.9640]\n",
      "Elapsed time [0:00:44], Iteration [190/5000], D/latent_real: [0.0002] D/latent_fake: [0.0039] D/latent_reg: [0.0038] D/ref_real: [0.0002] D/ref_fake: [0.0038] D/ref_reg: [0.0037] G/latent_adv: [6.5898] G/latent_sty: [0.4835] G/latent_ds: [0.7270] G/latent_cyc: [5.3790] G/ref_adv: [6.7022] G/ref_sty: [0.0195] G/ref_ds: [0.0110] G/ref_cyc: [5.3930] G/lambda_ds: [0.9620]\n",
      "Elapsed time [0:00:46], Iteration [200/5000], D/latent_real: [0.0100] D/latent_fake: [0.0001] D/latent_reg: [0.0040] D/ref_real: [0.0084] D/ref_fake: [0.0002] D/ref_reg: [0.0042] G/latent_adv: [11.1281] G/latent_sty: [0.4975] G/latent_ds: [0.6091] G/latent_cyc: [5.3706] G/ref_adv: [6.8449] G/ref_sty: [0.0232] G/ref_ds: [0.0158] G/ref_cyc: [5.3651] G/lambda_ds: [0.9600]\n",
      "Elapsed time [0:00:48], Iteration [210/5000], D/latent_real: [0.0108] D/latent_fake: [0.0085] D/latent_reg: [0.0031] D/ref_real: [0.0099] D/ref_fake: [0.0012] D/ref_reg: [0.0033] G/latent_adv: [13.7438] G/latent_sty: [0.5928] G/latent_ds: [0.5823] G/latent_cyc: [4.7091] G/ref_adv: [11.9080] G/ref_sty: [0.0130] G/ref_ds: [0.0038] G/ref_cyc: [4.7320] G/lambda_ds: [0.9580]\n",
      "Elapsed time [0:00:50], Iteration [220/5000], D/latent_real: [2.8982] D/latent_fake: [0.8075] D/latent_reg: [0.2935] D/ref_real: [0.0001] D/ref_fake: [8.2218] D/ref_reg: [0.0080] G/latent_adv: [3.0385] G/latent_sty: [0.4929] G/latent_ds: [0.7601] G/latent_cyc: [4.8196] G/ref_adv: [1.2998] G/ref_sty: [0.0107] G/ref_ds: [0.0053] G/ref_cyc: [4.8030] G/lambda_ds: [0.9560]\n",
      "Elapsed time [0:00:52], Iteration [230/5000], D/latent_real: [0.0396] D/latent_fake: [0.2569] D/latent_reg: [0.0016] D/ref_real: [4.0545] D/ref_fake: [0.0000] D/ref_reg: [0.0024] G/latent_adv: [1.0593] G/latent_sty: [0.5037] G/latent_ds: [0.5533] G/latent_cyc: [4.9687] G/ref_adv: [0.9715] G/ref_sty: [0.0144] G/ref_ds: [0.0132] G/ref_cyc: [4.9325] G/lambda_ds: [0.9540]\n",
      "Elapsed time [0:00:54], Iteration [240/5000], D/latent_real: [0.0002] D/latent_fake: [0.0035] D/latent_reg: [0.0105] D/ref_real: [0.0002] D/ref_fake: [0.0037] D/ref_reg: [0.0098] G/latent_adv: [8.2957] G/latent_sty: [0.4834] G/latent_ds: [0.7245] G/latent_cyc: [5.4409] G/ref_adv: [7.4868] G/ref_sty: [0.0148] G/ref_ds: [0.0097] G/ref_cyc: [5.6144] G/lambda_ds: [0.9520]\n",
      "Elapsed time [0:00:56], Iteration [250/5000], D/latent_real: [2.3508] D/latent_fake: [0.0005] D/latent_reg: [0.1115] D/ref_real: [0.4543] D/ref_fake: [0.6740] D/ref_reg: [0.0002] G/latent_adv: [0.7301] G/latent_sty: [0.6300] G/latent_ds: [0.5663] G/latent_cyc: [4.9745] G/ref_adv: [0.7346] G/ref_sty: [0.0099] G/ref_ds: [0.0043] G/ref_cyc: [4.9717] G/lambda_ds: [0.9500]\n",
      "Shape of source image: torch.Size([8, 3, 1024])\n",
      "Shape of reference image: torch.Size([8, 3, 1024])\n",
      "Shape of reference label: torch.Size([8]), value: tensor([3, 1, 2, 2, 1, 2, 3, 0], device='cuda:0')\n",
      "Shape of reference style: torch.Size([8, 8, 64])\n",
      "Into de torch: torch.Size([8, 3, 1024]) ==> tensor([[[-5.7577e-02, -4.1923e-01, -1.2885e+00,  ..., -8.6470e-01,\n",
      "          -1.8033e+00, -2.4505e+00],\n",
      "         [-1.1806e-01, -8.8544e-01, -2.8415e+00,  ...,  1.6173e+00,\n",
      "          -2.4821e+00, -4.8691e+00],\n",
      "         [-9.7840e-02, -7.2563e-01, -2.3225e+00,  ...,  2.8442e+00,\n",
      "          -2.2867e+00, -5.0302e+00]],\n",
      "\n",
      "        [[ 1.2907e-01,  9.9403e-01,  3.3849e+00,  ...,  6.1706e+00,\n",
      "           3.3830e+00,  7.1071e-01],\n",
      "         [ 6.5340e-02,  5.5537e-01,  2.1377e+00,  ...,  8.4903e+00,\n",
      "           7.4793e+00,  3.2073e+00],\n",
      "         [ 5.9230e-02,  5.2869e-01,  2.1032e+00,  ...,  8.3503e+00,\n",
      "           3.7051e+00, -3.3894e+00]],\n",
      "\n",
      "        [[-3.2300e-01, -2.7607e+00, -1.0283e+01,  ...,  3.1875e+00,\n",
      "           1.4262e+00,  2.4649e+00],\n",
      "         [-4.5111e-01, -3.6956e+00, -1.3195e+01,  ...,  3.4415e+00,\n",
      "           1.7760e+00,  1.0755e+00],\n",
      "         [-4.3991e-01, -3.5002e+00, -1.2114e+01,  ...,  2.7545e+00,\n",
      "          -6.2507e-01, -3.9030e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5717e-02, -1.8636e-01, -5.8704e-01,  ...,  3.9908e+00,\n",
      "           6.0521e+00,  7.3044e+00],\n",
      "         [-4.3620e-02, -3.1719e-01, -1.0340e+00,  ...,  3.8859e+00,\n",
      "           4.8752e+00,  5.9542e+00],\n",
      "         [-4.9330e-02, -3.5356e-01, -1.1212e+00,  ...,  2.5467e+00,\n",
      "           3.8659e+00,  6.0054e+00]],\n",
      "\n",
      "        [[-4.2609e-02, -2.8278e-01, -7.2388e-01,  ...,  1.2091e+01,\n",
      "           9.3480e+00,  5.6034e+00],\n",
      "         [-4.4667e-02, -3.1517e-01, -9.1351e-01,  ...,  1.1296e+01,\n",
      "           7.3541e+00,  2.9843e+00],\n",
      "         [-1.2088e-02, -6.1466e-02, -5.6044e-02,  ...,  1.1927e+01,\n",
      "           8.0776e+00,  3.6483e+00]],\n",
      "\n",
      "        [[ 1.1457e-01,  7.1689e-01,  1.8727e+00,  ..., -6.1103e+00,\n",
      "          -1.0019e+01, -7.2330e+00],\n",
      "         [ 5.9198e-02,  4.5351e-01,  1.5844e+00,  ..., -3.7013e+00,\n",
      "          -9.3141e+00, -8.4479e+00],\n",
      "         [-3.4780e-02, -2.3469e-01, -6.6289e-01,  ..., -4.6025e+00,\n",
      "          -6.2663e+00, -6.7775e+00]]], device='cuda:0')\n",
      "saving into expr/samples/000250_reference.jpg_07\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 90\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subdirs(args\u001b[38;5;241m.\u001b[39mval_img_dir)) \u001b[38;5;241m==\u001b[39m args\u001b[38;5;241m.\u001b[39mnum_domains\n\u001b[1;32m     73\u001b[0m loaders \u001b[38;5;241m=\u001b[39m Munch(src\u001b[38;5;241m=\u001b[39mget_train_loader(root\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_img_dir,\n\u001b[1;32m     74\u001b[0m                                         which\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     75\u001b[0m                                         img_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mimg_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m                                     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     89\u001b[0m                                     num_workers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_workers))\n\u001b[0;32m---> 90\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stargan-ssvep/core/solver.py:168\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self, loaders)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39msample_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    167\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(args\u001b[38;5;241m.\u001b[39msample_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 168\u001b[0m     \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnets_ema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# save model checkpoints\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39msave_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/starganV2/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stargan-ssvep/core/utils.py:199\u001b[0m, in \u001b[0;36mdebug_image\u001b[0;34m(nets, args, inputs, step)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# reference-guided image synthesis\u001b[39;00m\n\u001b[1;32m    198\u001b[0m filename \u001b[38;5;241m=\u001b[39m ospj(args\u001b[38;5;241m.\u001b[39msample_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%06d\u001b[39;00m\u001b[38;5;124m_reference.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (step))\n\u001b[0;32m--> 199\u001b[0m \u001b[43mtranslate_using_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/starganV2/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stargan-ssvep/core/utils.py:172\u001b[0m, in \u001b[0;36mtranslate_using_reference\u001b[0;34m(nets, args, x_src, x_ref, y_ref, filename)\u001b[0m\n\u001b[1;32m    169\u001b[0m     x_concat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [x_fake_with_ref]\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%02d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;250m \u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m--> 172\u001b[0m \u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m%02d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x_concat\n",
      "File \u001b[0;32m~/stargan-ssvep/core/utils.py:75\u001b[0m, in \u001b[0;36msave_image\u001b[0;34m(x, ncol, filename)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_image\u001b[39m(x, ncol, filename):\n\u001b[0;32m---> 75\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\n\u001b[1;32m     76\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_b\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     77\u001b[0m     ss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39msqrt(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from munch import Munch\n",
    "from torch.backends import cudnn\n",
    "import torch\n",
    "from core.data_loader import get_train_loader, get_test_loader\n",
    "from core.solver import Solver\n",
    "from core.wing import align_faces\n",
    "# import importlib\n",
    "\n",
    "# importlib.reload(get_train_loader)\n",
    "\n",
    "\n",
    "\n",
    "def subdirs(dname):\n",
    "    return [d for d in os.listdir(dname) if os.path.isdir(os.path.join(dname, d))]\n",
    "\n",
    "class Args:\n",
    "    img_size = 1024\n",
    "    num_domains = 4\n",
    "    latent_dim = 16\n",
    "    hidden_dim = 512\n",
    "    style_dim = 64\n",
    "    lambda_reg = 1\n",
    "    lambda_cyc = 1\n",
    "    lambda_sty = 1\n",
    "    lambda_ds = 1\n",
    "    ds_iter = 5000\n",
    "    w_hpf = 0 # For SSVEP\n",
    "    randcrop_prob = 0.5\n",
    "    total_iters = 5000\n",
    "    resume_iter = 0\n",
    "    batch_size = 8\n",
    "    val_batch_size = 8\n",
    "    lr = 5e-4\n",
    "    f_lr = 1e-6\n",
    "    beta1 = 0.0\n",
    "    beta2 = 0.99\n",
    "    weight_decay = 1e-4\n",
    "    num_outs_per_domain = 10\n",
    "    mode = 'train'\n",
    "    num_workers = 16\n",
    "    seed = 777\n",
    "    train_img_dir = 'data/train'\n",
    "    val_img_dir = 'data/val'\n",
    "    sample_dir = 'expr/samples'\n",
    "    checkpoint_dir = 'expr/checkpoints'\n",
    "    eval_dir = 'expr/eval'\n",
    "    result_dir = 'expr/results'\n",
    "    # src_dir = 'assets/representative/celeba_hq/src'\n",
    "    # ref_dir = 'assets/representative/celeba_hq/ref'\n",
    "    # inp_dir = 'assets/representative/custom/female'\n",
    "    # out_dir = 'assets/representative/celeba_hq/src/female'\n",
    "    # wing_path = 'expr/checkpoints/wing.ckpt'\n",
    "    # lm_path = 'expr/checkpoints/celeba_lm_mean.npz'\n",
    "    print_every = 10\n",
    "    sample_every = 250\n",
    "    save_every = 1000\n",
    "    eval_every = 2500\n",
    "    runType = 'w_4s'\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# print(args)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "solver = Solver(args)\n",
    "\n",
    "assert len(subdirs(args.train_img_dir)) == args.num_domains\n",
    "assert len(subdirs(args.val_img_dir)) == args.num_domains\n",
    "loaders = Munch(src=get_train_loader(root=args.train_img_dir,\n",
    "                                        which='source',\n",
    "                                        img_size=args.img_size,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        prob=args.randcrop_prob,\n",
    "                                        num_workers=args.num_workers),\n",
    "                ref=get_train_loader(root=args.train_img_dir,\n",
    "                                        which='reference',\n",
    "                                        img_size=args.img_size,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        prob=args.randcrop_prob,\n",
    "                                        num_workers=args.num_workers),\n",
    "                val=get_test_loader(root=args.val_img_dir,\n",
    "                                    img_size=args.img_size,\n",
    "                                    batch_size=args.val_batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=args.num_workers))\n",
    "solver.train(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starganV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
